

##' The Beta-Binomial Distribution
##' 
##' Density, distribution function, quantile function, and random generation
##' for the beta-binomial distribution.  A variable with a beta-binomial
##' distribution is distributed as binomial distribution with parameters
##' \code{N} and \code{p}, where the probability \code{p} of success itself has
##' a beta distribution with parameters \code{u} and \code{v}.
##' 
##' The beta-binomial distribution with parameters \eqn{N}, \eqn{u}, and
##' \eqn{v} has density given by \deqn{ choose(N, x) * Beta(x + u, N - x + v) /
##' Beta(u,v) } for \eqn{u > 0}, \eqn{v > 0}, a positive integer \eqn{N}, and
##' any nonnegative integer \eqn{x}. Although one can express the integral in
##' closed form using generalized hypergeometric functions, the implementation
##' of distribution function used here simply relies on the cumulative sum of
##' the density.
##' 
##' The mean and variance of the beta-binomial distribution can be computed
##' explicitly as \deqn{ mu = \frac{nu}/{u+v} } and \deqn{ sigma^2 =
##' \frac{nuv(n+u+v)}{(u+v)^2 (1+u+v)} }
##' 
##' @aliases dbb pbb qbb rbb
##' @usage dbb(x, N, u, v) pbb(q, N, u, v) qbb(p, N, u, v) rbb(n, N, u, v)
##' @param x vector of qauntiles
##' @param q vector of quantiles
##' @param p vector of probabilities
##' @param n number of observations
##' @param N number of trials (a positive integer)
##' @param u first positive parameter of the beta distribution
##' @param v second positive parameter of the beta distribution
##' @return \code{dbb} gives the density, \code{pbb} gives the distribution
##' function, \code{qbb} gives the quantile function, and \code{rbb} generates
##' random deviates.
##' @note \code{dbb} and \code{qbb} do not recycle vector-valued arguments in
##' the usual fashion in R.  Arguments to these functions must have length 1
##' and/or one other length. See example of \code{\link{pcbinom}} for more
##' information.
##' 
##' Non integer values of \code{x} and \code{N} are rounded to the nearest
##' integer with a warning.
##' @section Warning: \code{dbb}, \code{pbb}, and \code{qbb} can be imprecise
##' when the probabilities for tail values are small.  This can result in
##' unusual behavior for \code{pbb} and \code{qbb}.
##' @author Kevin R. Coombes, modified by Landon Sego
##' @seealso \code{\link{dbeta}} for the beta distribution and
##' \code{\link{dbinom}} for the binomial distribution.
##' @keywords misc
##' @examples
##' 
##' # set up parameters
##' w <- 10
##' u <- 0.3*w
##' v <- 0.7*w
##' N <- 12
##' 
##' # generate random values from the beta-binomial
##' x <- rbb(1000, N, u, v)
##' 
##' # check that the empirical summary matches the theoretical one
##' summary(x)
##' qbb(c(0.25, 0.50, 0.75), N, u, v)
##' 
##' # check that the empirical histogram matches the theoretical density
##' hist(x, breaks=seq(-0.5, N + 0.55), prob=TRUE)
##' lines(0:N, dbb(0:N, N, u,v), type='b')
##' 
##' # An example of the imprecision in pbb and qbb:  we would expect
##' # this to return 0:29
##' qbb(pbb(0:29, 29, 1, 33), 29, 1, 33)
##' 
NULL





##' 2-step Chebyshev outlier detection
##' 
##' Uses a 2-step (unimodal and/or one-sided) Chebyshev outlier detection to
##' identify outliers or unusual values.
##' 
##' In the first step, the Chebyshev limit is used to filter gross outliers
##' from the data.  The filtered data are then used to estimate the mean and
##' standard deviation that are used to contruct the Chebyshev limits during
##' the second step.  This way, the estimates of the mean and standard
##' deviation are not unduly influenced by large outliers.
##' 
##' When \code{zero.variance.correction=TRUE}, outliers identified on the first
##' pass are set equal to the first Chebyshev limit (instead of being removed)
##' if removing those outliers creates a filtered data vector that has 0
##' variance.  This ensures that the filtered data set (used for the second
##' step) does not have zero variance.
##' 
##' @usage cheb.2step.od(the.vector, unimodal = TRUE, first.rejval = 1/1000,
##' second.rejvals = c(1/100, 1/1000, 1/10000), do.plot = FALSE,
##' zero.var.correction = TRUE, one.sided = NULL, ...)
##' @param the.vector Vector of numeric data
##' @param unimodal \code{=TRUE} assumes the data come from a unimodal
##' distribution
##' @param first.rejval A numerical probability cutoff value used to identify
##' the initial Chebyshev limits that will filter the data for the calculation
##' of the second step Chebyshev limits
##' @param second.rejvals A vector of probability cutoff values that are used
##' in the second application of the Chebychev filter
##' @param do.plot \code{=TRUE} produces a histogram that shows the data, the
##' first step Chebyshev limit in gray and the second Chebyshev limits in blue.
##' @param zero.var.correction \code{=TRUE} ensures that the filtered data set
##' (used for the second step) does not have zero variance.  See Details.
##' @param one.sided if "upper" (or "lower"), it calculates a one-sided upper
##' (or lower) Chebyshev limit (in both steps) instead of the usual two-sided
##' limit.  Defaults to \code{NULL}, which produces the two-sided limit.
##' @param \dots Additional arguments to \code{my.histogram}
##' @return A list with the following components \item{output}{A matrix with
##' the requested second step probabilities and the second step Chebyshev
##' limits} \item{removed.in.step1}{Shows the data points that were filtered
##' and not used in calculating the Chebyshev limits in step 2}
##' \item{step1.cv}{A matrix with the requested first step probabilities and
##' the first step Chebyshev limits}
##' @author Brett Amidan with additions from John Hathway and Landon Sego
##' @seealso \code{\link{cheb.od}}
##' @keywords misc
##' @examples
##' 
##' # Unimodal, 2-sided example from the Cauchy distribution
##' cheb.2step.od(rt(500, df=1), first.rejval=0.01, second.rejvals=10^(-2:-5))
##' 
##' # Unimodal, 1-sided upper example using a mixture of Gamma variates
##' cheb.2step.od(c(rgamma(200, shape=10, scale=20), rgamma(5, shape=10, scale=500)),
##'               first.rejval=0.01, one.sided="upper")
##' 
##' # Unimodal, 1-sided lower example using a mixture of Gamma variates
##' cheb.2step.od(-1 * c(rgamma(200, shape=10, scale=20), rgamma(5, shape=10, scale=500)),
##'               first.rejval=0.01, one.sided="lower")
##' 
##' 
NULL





##' Calculates the Chebysehev limit for a vector of data
##' 
##' Calculates the lower, upper, one-sided upper, and one-sided lower Chebyshev
##' limits for a vector of data.
##' 
##' When \code{unimodal = TRUE}, the Vysochanskiï-Petunin inequality is used.
##' Otherwise, the traditional Chebyshev inequality is used.
##' 
##' @usage cheb.od(the.data, unimodal = TRUE, rej.val = c(1/100, 1/1000,
##' 1/10000))
##' @param the.data A numeric vector of data
##' @param unimodal \code{=TRUE} indicates the assumption that the data come
##' from a unimodal distribution
##' @param rej.val A vector of probability cutoff values
##' @return A matrix, one row per \code{rej.value}, with the following columns:
##' \item{probabilities}{The probabilities from \code{rej.value}}
##' \item{lower.cv}{The lower Chebyshev limit} \item{upper.cv}{The upper
##' Chebyshev limit} \item{one.sided.upper.cv}{The one-sided upper Chebyshev
##' limit} \item{one.sided.lower.cv}{The one-sided lower Chebyshev limit}
##' @author Brett Amidan with additions from John Hathway and Landon Sego
##' @seealso \code{\link{cheb.2step.od}}
##' @references For the Chebyshev inequality, see:
##' 
##' http://en.wikipedia.org/wiki/Chebyshev\%27s_inequality
##' 
##' The unimodal Chebyshev inequality is known as the Vysochanskiï-Petunin
##' inequality.  See:
##' 
##' http://en.wikipedia.org/wiki/Vysochanski\%C3\%AF-Petunin_inequality
##' 
##' Also see:
##' 
##' http://ieeexplore.ieee.org/iel5/10432/33126/01559688.pdf?arnumber=1559688
##' @keywords misc
##' @examples
##' 
##' 
##' # Unimodal, normal example
##' cheb.od(rnorm(500), rej.val=10^(-2:-5))
##' 
##' # Bimodal example
##' cheb.od(c(rnorm(300), rnorm(300, 4, 1)), unimodal=FALSE)
##' 
##' 
NULL





##' Determine the status of an R batch job running in the background
##' 
##' Determine the status of an R batch job running in the background. Useful if
##' other processes need to wait on the completion of another job.
##' 
##' If \code{proc.time()} is found in the .Rout file, the job is considered to
##' have completed successfully.  If \code{Execution halted} is found, the job
##' is considered to have failed.  If neither is found, the job is considered
##' to be still running.
##' 
##' @usage checkBatch(file, check.interval.sec = 2, max.hours = 24, wait =
##' TRUE)
##' @param file The filename of a .Rout file from an R batch job.
##' @param check.interval.sec The number of seconds to wait between checking to
##' see whether the job has completed.
##' @param max.hours The maximum number of hours to wait for the job to
##' complete.
##' @param wait \code{=TRUE} indicates that \code{checkBatch} will wait until
##' the job complete.  If \code{FALSE}, it does not wait and simply returns the
##' status of the job.
##' @return A text string with one of 3 values: \item{success}{If the job has
##' completed successfully} \item{fail}{If the job has failed}
##' \item{incomplete}{If the job is still running}
##' @author Landon Sego
##' @keywords misc
##' @examples
##' 
##' # This example designed for Unix
##' # Make a quick batch file and launch it
##' cat("mean(rnorm(5*10^7))", file="test_checkBatch_tmp.R")
##' 
##' # Run this manually...
##' system("R CMD BATCH test_checkBatch_tmp.R", wait=FALSE)
##' 
##' # Wait briefly for the job to launch
##' Sys.sleep(0.5)
##' 
##' # This one, if lauched immediately after the system call above, shoul
##' # return "incomplete"
##' checkBatch("test_checkBatch_tmp.Rout", wait = FALSE)
##' 
##' # This one should wait until it finishes and return "success"
##' checkBatch("test_checkBatch_tmp.Rout", check.interval.sec = 1, max.hours = 0.1)
##' 
##' # Delete temporary files
##' unlink(c("test_checkBatch_tmp.R", "test_checkBatch_tmp.Rout"))
##' 
NULL





##' Filename manipulations: remove the extension or path, extract the extension
##' or path
##' 
##' Functions to 1) remove the filename extension 2) extract the filename
##' extention, 3) strip off the leading path, 4) extract the path, or 5)
##' extract the last portion of a string that follows a delimiter--from a
##' vector of filenames.
##' 
##' Assumes paths are delineated using forward slashes.  If an \code{NA} is
##' supplied, then an \code{NA} is returned.  If the desired string doesn't
##' exist (see examples below), a \code{""} is returned.
##' 
##' @aliases stripExtension getExtension stripPath getPath grabLast
##' @usage stripExtension(vec, split.char = ".") getExtension(vec)
##' stripPath(vec) getPath(vec) grabLast(vec, split.char)
##' @param vec Character vector (usually containing filenames)
##' @param split.char A single character used to split the character strings
##' @return \item{stripExtension}{Character vector with the last "." and the
##' filename extension removed.  Alternatively, another split character could
##' be used.} \item{getExtension}{Character vector of filename extensions}
##' \item{stripPath}{Character vector with leading path removed from the
##' filenames} \item{getPath}{Character vector with pathnames only, the
##' filename removed} \item{grabLast}{Character vector of the strings that
##' appear after the last instance of \code{split.char}}
##' @author Landon Sego
##' @seealso \code{\link{basename}}, \code{\link{dirname}}
##' @keywords misc
##' @examples
##' 
##' stripExtension(c("this old file.doc","that young file.rtf",
##'                  "this.good.file.doc","this_bad_file"))
##' 
##' stripExtension(c("this old file*doc","that young file*rtf",
##'                  "this*good*file*doc","this_bad_file"), split.char = "*")
##' 
##' 
##' # Named vectors are not required, but are included here to make the
##' # output easier to read.  This example demonstrates a number of
##' # pathological cases.
##' stripExtension(c(a = NA, b = ".doc", c = "this.pdf", d = "this.file.", e = ".",
##'                  f= "noExtension", g = "direc.name/filename.txt", h = ""))
##' 
##' getExtension(c(a="this old file.doc", b="that young file.rtf",
##'                c="this.good.file.doc", d="this_bad_file", e="thisfile.",
##'                f=NA, g="that.this.pdf", h=".", i=""))
##' 
##' stripPath(c(a="this.good.path/filename.R", b="nopath.R", c="/", d=NA,
##'             e="only.paths.1/only.paths.2/", ""))
##' 
##' getPath(c(a="this.good.path/filename.R", b="nopath.R", c="/", d=NA,
##'           e="path1/path2/", ""))
##' 
##' grabLast(c(a="email@nowhere.com", "this.has.no.at.sign", "@",
##'              "bad.email@weird.com@", NA, "2at's@email@good.net"), "@")
##' 
##' # An example with 'real' files
##' files <- dir(paste(path.package(package="pnlStat"), "SourceCode/R", sep="/"), full.names=TRUE)[1:5]
##' print(files)
##' stripExtension(files)
##' stripPath(files)
##' stripExtension(stripPath(files))
##' stripPath(stripExtension(files))
##' 
NULL





##' Finds the level of numerical equivalence of two dataframes or matrices
##' 
##' Wrapper function for \code{dframeEquiv} that identifies the smallest
##' \code{maxAbsError} and \code{maxRelError} for which two data frames or
##' matrices are still equivalent
##' 
##' The function tests the equivalence of \code{d1} and \code{d2} over the
##' matrix of combinations of \code{maxAbsError} and \code{maxRelError}, each
##' with values \code{1e-minPrec, 1e-(minPrec+1), ..., 1e-(maxPrec-1),
##' 1e-maxPrec}.
##' 
##' @usage find.dframeEquiv(d1, d2, minPrec = 5, maxPrec = 15, returnMatrix =
##' FALSE)
##' @param d1 The first dataframe or matrix
##' @param d2 The dataframe or matrix that will be compared to \code{d1}
##' @param minPrec An integer ranging from 0 to 22 indicating the smallest
##' exponent in \code{maxAbsError} and \code{maxRelError} that will be
##' considered
##' @param maxPrec An integer ranging from 1 to 22 indicating the largest
##' exponent in \code{maxAbsError} and \code{maxRelError} that will be
##' considered.  It must be larger than \code{minPrec}.
##' @param returnMatrix \code{=TRUE} returns a boolean matrix indicating the
##' result of the comparison for the various combinations of \code{maxAbsError}
##' and \code{maxRelError}
##' @return If \code{d1} is not equal to \code{d2} when
##' \code{maxAbsError=1e-minPrec} and \code{maxRelError=1e-minPrec} then
##' \code{NULL} is returned, along with the message that describes the
##' inequality. Otherwise, a list with the following components is returned:
##' 
##' \item{leastAbsError}{A named vector indicating values of the the smallest
##' \code{maxAbsError} and the corresponding \code{maxRelError} that resulted
##' in equivalence} \item{leastRelError}{A named vector indicating values of
##' the the smallest \code{maxRelError} and the corresponding
##' \code{maxAbsError} that resulted in equivalence} \item{returnMatrix}{A
##' boolean matrix whose rows (and rownames) correspond to the exponents of the
##' \code{maxAbsError} and whose columns (and colnames) correspond to the
##' exponents of the \code{maxRelError}.  Values of \code{TRUE} indicate
##' combinations of \code{maxMaxError} and \code{maxRelError} for which the two
##' dataframes/matrices were equivalent.}
##' @author Landon Sego
##' @seealso \code{\link{dframeEquiv}}
##' @keywords misc
##' @examples
##' 
##' # Number of rows different
##' a <- matrix(rnorm(20), nrow=4)
##' b <- a[1:3,]
##' find.dframeEquiv(a, b)
##' 
##' # Equivalent
##' x <- data.frame(x=letters[1:6], y=rnorm(6), z=rnorm(6))
##' y <- x
##' find.dframeEquiv(x, y)
##' 
NULL





##' Kill a SLURM job from R
##' 
##' Kill a SLURM job from R using \code{scancel job.id}
##' 
##' If the job is not present in the queue, then \code{scancel} command is not
##' issued.  This function is used for error control in
##' \code{\link{piclapply}}.
##' 
##' @usage killSlurm(job.id)
##' @param job.id SLRUM job number.  May be passed as a numeric value or as a
##' string.
##' @return Nothing.  Only a message indicating whether or not the job was
##' canceled.
##' @author Landon Sego
##' @seealso \code{\link{piclapply}}.
##' @keywords misc
NULL





##' Probability functions for the sum of two independent binomials
##' 
##' The mass and distribution functions of the sum of two independent binomial
##' random variables.
##' 
##' If \code{prob1} and \code{prob2} are the same, then \code{pbinom} or
##' \code{dbinom} is used.  Otherwise, the convolution of the two binomials is
##' used to calculate the mass or the distribution functions.
##' 
##' NOTE: When \code{log.p} or \code{log} is \code{TRUE}, these functions do
##' not have the same precision as \code{dbinom} or \code{pbinom} when the
##' probabilities are very small, i.e, the values tend to go to \code{-Inf}
##' more quickly.
##' 
##' @aliases d2binom p2binom
##' @usage d2binom(x, size1, prob1, size2, prob2, log = FALSE) p2binom(q,
##' size1, prob1, size2, prob2, lower.tail = TRUE, log.p = FALSE)
##' @param q The quantile (value at which to evaluate the distribution
##' function)
##' @param x The value at which to evaluate the mass function
##' @param size1 The number of trials of the first binomial R.V.
##' @param prob1 The probability of success of the first binomial R.V.
##' @param size2 The number of trials of the second binomial R.V.
##' @param prob2 The probability of success of the second binomial R.V.
##' @param lower.tail logical; if \code{TRUE} (default), probabilities are P[X
##' <= x], otherwise, P[X > x].
##' @param log,log.p logical; if TRUE, probabilities p are given as log(p).
##' (See NOTE in details).
##' @return \code{d2binom} gives the mass function, \code{p2binom} gives the
##' distribution function.  Returns \code{NaN} for invalid inputs of
##' \code{size1}, \code{size2}, \code{prob1}, and \code{prob2}.
##' @author Landon Sego
##' @seealso \code{\link{dbinom}}, \code{\link{pbinom}}, \code{\link{dkbinom}},
##' \code{\link{pkbinom}}
##' @keywords misc
##' @examples
##' 
##'  d2binom(8, 10, 0.3, 17, 0.1)
##'  p2binom(8, 10, 0.3, 17, 0.1)
##'  p2binom(8, 10, 0.3, 17, 0.1, lower.tail = FALSE, log.p = TRUE)
##' 
NULL





##' High performance computing (HPC) parallelization of lapply on PIC
##' 
##' Parses a list into subsets and submits a separate R job using lapply() or
##' mclapply() for each subset. Jobs are executed using parallelized high
##' performance computing on the PNNL institutional computing cluster (PIC):
##' olympus.pnl.gov.  The parallel jobs are instantiated on multiple
##' nodes/cores using a SLURM batch job.
##' 
##' \code{piclapply} applies \code{FUN} to each element of the list \code{X} by
##' parsing the list into sublists of equal (or almost equal) size (using
##' \code{\link{parseJob}}) and then applying \code{FUN} to each sublist using
##' \code{\link{lapply}} or \code{\link{mclapply}}. In the case of the former,
##' the list, \code{X}, will be parsed using \code{\link{parseJob}} into
##' \code{32*numNodes} sublists, each of which will be processed by
##' \code{\link{lapply}} on a separate core in its own instance of R.  For the
##' latter, \code{X} is parsed into \code{numNodes} sublists, each of which is
##' is processed as a single instance of R on each node using
##' \code{\link{mclapply}}.
##' 
##' In general, the option \code{use.mclapply = TRUE} should be more efficient
##' because the R environment only has to be recreated once for each node,
##' instead of once for each core. But, when using \code{use.mclapply = TRUE},
##' be sure that either 1) the list, \code{X}, is large enough so that each
##' core will have at least one element of the list to process (e.g.
##' \code{length(X) >= 32 * numNodes}), or 2) the computational workload of
##' \code{FUN} is large enough so as to utilize all 32 cores of each node.
##' Note that \code{\link{mclapply}} is capable of recursion--so \code{FUN}
##' could contain a call to \code{\link{mclapply}}.
##' 
##' For \code{use.mclapply = TRUE}, if the length of the list is shorter than
##' \code{numNodes}, then the number of nodes is reduced so that each element
##' of \code{X} is assigned to a single node. For \code{use.mclapply = FALSE},
##' if the length of the list is shorter than the number of requested cores
##' (which is \code{32 * numNodes}), then the number of nodes is reassigned to
##' a value that will utilize full nodes to the extent possible, and a warning
##' is displayed.
##' 
##' After calling \code{piclapply}, it is also good practice to log into one
##' (or more) of the nodes that are assigned by SLURM and verify (using
##' \code{top}) that all of the cores are computing as expected.
##' 
##' After the jobs complete, the output lists are reassembled in the order of
##' the original input list, \code{X}.
##' 
##' A number of objects are made available in the global environment of each
##' instance of R.  These objects can be used by \code{FUN} if needed.  They
##' are:
##' 
##' \itemize{
##' 
##' \item \code{process.id}: An integer uniquely identifying the process of R
##' that is running.  For \code{use.mclapply = TRUE}, this will range from 0 to
##' \code{numNodes - 1}.  For \code{use.mclapply = FALSE}, this will range from
##' 0 to \code{32 * numNodes - 1}. \item \code{num.slurm.processes}: The total
##' number of R instances launched by SLURM.  In general, if \code{use.mclapply
##' = TRUE}, then this will be equal to \code{numNodes}.  If \code{use.mclapply
##' = FALSE}, then this will be \code{32 * numNodes}. \item \code{wkdir.out}: A
##' character string indicating the directory where output from each R instance
##' is saved
##' 
##' }
##' 
##' Each instance of R runs a script that performs the following steps:
##' 
##' \enumerate{
##' 
##' \item The \code{pnlStat} package is loaded.
##' 
##' \item The \code{parallel} package is loaded if \code{mclapply = TRUE}.
##' 
##' \item Any other packages indicated in the \code{packages} argument are
##' loaded.
##' 
##' \item The \code{process.id} global variable is assigned (having been passed
##' in via a command line argument).  This variable identifies the particular
##' instance of R.
##' 
##' \item The header file (if there is one) is sourced.
##' 
##' \item The R environment file is loaded, which contains the list, \code{X},
##' the function \code{FUN}, any \code{needed.objects}, as well as all other
##' objects (internally created by \code{piclapply}) that will be needed.
##' 
##' \item The expression \code{pre.process.expression} is evaluated if an
##' object of that name is present in the global environment. The object
##' \code{pre.process.expression} may be passed in via the header file or via
##' \code{needed.objects}.
##' 
##' \item The subset of the indexes of the list \code{X} (that will create the
##' sublist) is identified for the particular instance of R, using the
##' \code{process.id} variable.
##' 
##' \item The sublist, \code{X.sub}, of the list \code{X} is created and
##' \code{X} is removed to save memory.
##' 
##' \item \code{\link{lapply}} or \code{\link{mclapply}} is called as follows:
##' \code{X.sub.out <- lapply(X.sub, FUN.p)}, where \code{FUN.p} is a wrapper
##' to \code{FUN} containing named arguments.
##' 
##' \item The expression \code{post.process.expression} is evaluated if an
##' object of that name is present in the global environment.  The object
##' \code{post.process.expression} may be passed in via the header file or via
##' \code{needed.objects}.  This is a way you can reduce the output in
##' \code{X.sub.out}.
##' 
##' \item The list \code{X.sub.out} is saved to a file in \code{wkdir.out}
##' where it will be collected after all jobs have completed.
##' 
##' \item Warnings are printed. }
##' 
##' @usage piclapply(X, FUN, account, ..., packages = NULL, header.file = NULL,
##' needed.objects = NULL, needed.objects.env = parent.frame(), jobName =
##' "piclapply", numNodes = 2, partition = c("slurm", "short", "fat", "gpu"),
##' time.limit.mins = 30, check.interval.sec = 30, tarball.file = NULL,
##' use.mclapply = FALSE, mclapply.args = NULL, parseJob.args = NULL,
##' remove.working.dir = TRUE, email.notification = NULL, verbose = FALSE)
##' @param X The list, each element of which will be the input to \code{FUN}
##' @param FUN A function whose first argument is an element of list \code{X}
##' @param account A character string indicating the PIC account (e.g. "CSI",
##' "SDI", "USERS") that will charged for the computing time.
##' @param \dots Additional named arguments to \code{FUN}
##' @param packages Character vector giving the names of packages that will be
##' loaded in each new instance of R. If \code{NULL}, no packages are loaded
##' for each new instance of R.
##' @param header.file Text string indicating a file that will be initially
##' sourced prior calling \code{\link{lapply}} in order to create an
##' 'environment' that will satisfy all potential dependencies for \code{FUN}.
##' If \code{NULL}, no file is sourced.
##' @param needed.objects Character vector giving the names of objects which
##' reside in the evironment specified by \code{needed.objects.env} that may be
##' needed by \code{FUN}.  These objects are loaded into the GLOBAL ENVIRONMENT
##' of each new instance of R that is launched.  If \code{NULL}, no additional
##' objects are passed the the global environment of the various R instances.
##' @param needed.objects.env Environment where \code{needed.objects} reside.
##' This defaults to the environment in which \code{plapply} is called.
##' @param jobName Text string indicating the prefix for files and folders that
##' will be created while launching the separate instances of R.
##' @param numNodes Integer indicating the number of nodes requested for
##' parallel processing. Each node on olympus has 32 cores. So, for example,
##' requesting 3 nodes is equivalent to requesting 96 parallel jobs.
##' @param partition Character string indicating the PIC partition to which the
##' job should be submitted. May be abbreviated.  Defaults to \code{slurm},
##' which is the partition for 'usual' jobs.  The \code{short} partition is for
##' testing and code development for short jobs of 1 hour or less. The
##' \code{fat} partition contain nodes with more memory, and the \code{gpu}
##' partition contains nodes with GPU capability.  Use the system command
##' \code{sview} to see a graphical depiction of the entire cluster and to see
##' more detailed information about the partitions.
##' @param time.limit.mins Integer indicating the time limit (in minutes) of
##' the SLURM batch job. If the SLURM job exceeds this limit it will be
##' canceled.  However, jobs with shorter limits are likely to be scheduled for
##' launch sooner.
##' @param check.interval.sec The number of seconds to wait between checking to
##' see whether the SLURM batch job has completed.
##' @param tarball.file A text string indicating the file (ending in .tar.gz)
##' where all the files used to create and support the SLURM job will be
##' stored.  If \code{NULL}, a file of the form 'jobName_output_####.tar.gz'
##' will be stored in the working directory.  If \code{tarball.file = "none"},
##' no tarball will be created.
##' @param use.mclapply \code{= TRUE} uses the \code{\link{mclapply}} function
##' from the \code{parallel} package to distribute the work to the 32 cores
##' within a node, and only one instance of R is launched on each node. If
##' \code{use.mclapply = FALSE}, a separate instance of R (via a system batch
##' call) is launched on each core. See Details.
##' @param mclapply.args A named list of optional (named) arguments to
##' \code{\link{mclapply}}.  If \code{mclapply.args = NULL}, the default
##' arguments of \code{\link{mclapply}} are used (provided \code{use.mclapply =
##' TRUE}).
##' @param parseJob.args A named list of optional (named) arguments to
##' \code{\link{parseJob}} If \code{parseJob.args = NULL}, the default
##' arguments of \code{\link{parseJob}} are used.
##' @param remove.working.dir \code{= TRUE} requests the working directory of
##' the SLURM job files be deleted on successful completion.  If the SLURM job
##' fails, this directory will not be removed.
##' @param email.notification Text string containing an email address to which
##' an email will be sent upon completion of the SLURM job.  If \code{NULL}, no
##' email will be sent.
##' @param verbose \code{= TRUE} prints details (and timing) of the job
##' @return A list equivalent to that returned by \code{lapply(X, FUN, ...)}.
##' @author Landon Sego
##' @seealso \code{\link{lapply}}, \code{\link{mclapply}},
##' \code{\link{plapply}}, \code{\link{dfplapply}}
##' @keywords misc
##' @examples
##' 
##' ########################################
##' # Example 1
##' ########################################
##' 
##' # Note:  you may need to change the account name
##' account.name <- "USERS"
##' 
##' # Create a simple list
##' a <- list(a = rnorm(10), b = rnorm(20), c = rnorm(15), d = rnorm(13), e = rnorm(15), f = rnorm(22))
##'      
##' # Some objects that will be needed by f1:
##' b1 <- rexp(20)
##' b2 <- rpois(10, 20)
##'      
##' # The function
##' f1 <- function(x) mean(x) + max(b1) - min(b2)
##'      
##' # Call piclapply
##' res.1 <- piclapply(a, f1, account.name,
##'                    needed.objects = c("b1", "b2"),
##'                    jobName = "example.1",
##'                    numNodes = 1,
##'                    partition = "short",
##'                    check.interval.sec = 1,
##'                    time.limit.mins = 1,
##'                    use.mclapply = TRUE,
##'                    tarball.file = "none",
##'                    verbose = TRUE)
##' 
##' # Call lapply to check the results
##' res.2 <- lapply(a, f1)
##' print(res.2)
##'      
##' # Compare results
##' all.equal(res.1, res.2)
##' 
##' 
##' ########################################
##' # Example 2
##' ########################################
##' 
##' # Create a function that calculates the mean of a normal variate
##' mean.tmp <- function(list.element, sigma = 1) {
##'   set.seed(list.element)
##'   mean(rnorm(500, mean = list.element, sd = sigma))
##' }
##' 
##' # Create a list of means (and seeds) to operate over
##' aList <- as.list(0:10000)
##' 
##' # Create a useless header file just for demonstration
##' cat("noUse <- rnorm(100)\n", file = "tmp.hdr.R")
##' 
##' # Use mclapply()
##' res.3 <- piclapply(aList, mean.tmp, account.name, sigma = 0.5,
##'                    # These packages aren't really needed.  Just
##'                    # illustrating how to include them
##'                    packages = c("MASS", "nlme"),  
##'                    header.file = "tmp.hdr.R",
##'                    jobName = "example.2",
##'                    time.limit.mins = 1,
##'                    numNodes = 2,
##'                    partition = "short",
##'                    # An silly example of controling the parameters for mclapply...
##'                    use.mclapply = TRUE,
##'                    mclapply.args = list(mc.cores = 20),
##'                    check.interval.sec = 1,
##'                    tarball.file = "none",
##'                    verbose = TRUE)
##' 
##' unlink("tmp.hdr.R")
##' 
##' # Rerun it, except this time don't use mclapply(), illustrate additional
##' # arguments to parseJob().  Notice the warning regarding 'nunNodes'
##' # being too large.
##' res.4 <- piclapply(aList, mean.tmp, account.name, sigma = 0.5,
##'                    jobName = "example.2",
##'                    time.limit.mins = 1,
##'                    numNodes = 3,
##'                    partition = "short",
##'                    parseJob.args = list(collate = TRUE, text.to.eval = TRUE),
##'                    check.interval.sec = 1,
##'                    tarball.file = "none",
##'                    verbose = TRUE)
##' 
##' head(res.3)
##' tail(res.3)
##' 
##' # These should be the same...
##' all.equal(res.3, res.4)
##' 
##' 
NULL





##' Probability functions for the sum of k independent binomials
##' 
##' The mass and distribution functions of the sum of k independent binomial
##' random variables, with possibly different probabilities.
##' 
##' \code{size[1]} and \code{prob[1]} are the size and probability of the first
##' binomial variate, \code{size[2]} and \code{prob[2]} are the size and
##' probability of the second binomial variate, etc.
##' 
##' If the elements of \code{prob} are all the same, then \code{pbinom} or
##' \code{dbinom} is used.  Otherwise, repeating convolutions of the k
##' binomials are used to calculate the mass or the distribution functions.
##' 
##' NOTE: When \code{log.p} or \code{log} is \code{TRUE}, these functions do
##' not have the same precision as \code{dbinom} or \code{pbinom} when the
##' probabilities are very small, i.e, the values tend to go to \code{-Inf}
##' more quickly.
##' 
##' @aliases dkbinom pkbinom
##' @usage dkbinom(x, size, prob, log = FALSE, verbose = FALSE) pkbinom(q,
##' size, prob, log.p = FALSE, verbose = FALSE)
##' @param q Vector of quantiles (value at which to evaluate the distribution
##' function) of the sum of the k binomial variates
##' @param x Vector of values at which to evaluate the mass function of the sum
##' of the k binomial variates
##' @param size Vector of the number of trials
##' @param prob Vector of the probabilities of success
##' @param log,log.p logical; if TRUE, probabilities p are given as log(p).
##' (See NOTE in details).
##' @param verbose \code{= TRUE} produces output that shows the iterations of
##' the convolutions and 3 arrays, A, B, and C that are used to convolve and
##' reconvolve the distributions.  Array C is the final result.  See the source
##' code in \code{dkbinom.c} for more details.
##' @return \code{dkbinom} gives the mass function, \code{pkbinom} gives the
##' distribution function.  Produces errors for invalid inputs of \code{size},
##' \code{prob}, \code{x}, and \code{q}.
##' @author Landon Sego
##' @seealso \code{\link{dbinom}}, \code{\link{pbinom}}, \code{\link{d2binom}},
##' \code{\link{p2binom}}
##' @references Based on the exact algorithm discussed by
##' 
##' Butler, Ken and Stephens, Michael. (1993) The Distribution of a Sum of
##' Binomial Random Variables. Technical Report No. 467, Department of
##' Statistics, Stanford University.
##' 
##' \url{http://statistics.stanford.edu/~ckirby/techreports/ONR/SOL%20ONR%20467.pdf}
##' @keywords misc
##' @examples
##' 
##'  dkbinom(8, c(10, 17), c(0.3, 0.1))
##'  # Compare with p2binom
##'  d2binom(8, 10, 0.3, 17, 0.1)
##' 
##'  dkbinom(c(0, 7), c(3, 4, 2), c(0.3, 0.5, 0.8))
##'  pkbinom(c(0, 7), c(3, 4, 2), c(0.3, 0.5, 0.8), verbose = TRUE)
##' 
NULL





##' A collection of miscellaneous functions
##' 
##' Collection of convenient functions used in the PNNL Stat Group
##' 
##' \tabular{ll}{ Package: \tab pnlStat\cr Type: \tab Package\cr Version: \tab
##' 2013.03.12\cr Date: \tab 2013-03-12\cr License: \tab Unknown \cr }
##' 
##' @name pnlStat
##' @docType package
##' @author Members of the PNNL Statistical Sciences group
##' 
##' Maintainer: Landon Sego <Landon.Sego@@pnl.gov>
##' @keywords package
NULL





##' An example of power data
##' 
##' A small, altered, subset of total rack power for one of the racks in a data
##' center, to be used for illustration.
##' 
##' 
##' @name PowerData
##' @docType data
##' @usage data(PowerData)
##' @format The format is: Named num [1:12] 5.15 5.15 5.15 5.16 5.16 ...  -
##' attr(*, "names")= chr [1:12] "2008-05-06 17:00:01" "2008-05-06 17:00:17"
##' "2008-05-06 17:00:21" "2008-05-06 17:00:32" ...
##' @keywords datasets
##' @examples
##' 
##' data(PowerData)
##' print(PowerData)
##' rm(PowerData, envir=.GlobalEnv)
##' 
NULL





##' Generic data frame with a time variable
##' 
##' Generic data frame with a time variable to support the example in
##' \code{\link{smartTimeAxis}}.
##' 
##' 
##' @name timeData
##' @docType data
##' @usage data(timeData)
##' @format A data frame with 414 observations on the following 2 variables.
##' \describe{ \item{list("time")}{a POSIXt} \item{list("x")}{a numeric vector}
##' }
##' @keywords datasets
##' @examples
##' 
##' data(timeData)
##' 
NULL





##' Four short time series
##' 
##' Four short times series for use in the \code{\link{timeDiff}} example.
##' 
##' 
##' @name timeDiff.eg
##' @docType data
##' @keywords datasets
##' @examples
##' 
##' data(timeDiff.eg)
##' 
NULL



